{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/gd1m3y/Data_scraping/blob/main/scrapping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZMUTEBujDHbK"
   },
   "source": [
    "#Scrapping text data\n",
    "[first function](https://colab.research.google.com/drive/1N2auJ9eEg2HdfKn8lSSLFTLSj55m4810#scrollTo=VEmaRLOV2BqA&line=33&uniqifier=1)\n",
    "[second Function]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "GJNA4D2pnzj9"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "8mx583ecqnd3"
   },
   "outputs": [],
   "source": [
    "test_url = \"https://muckrack.com/beat/bizfin\"\n",
    "test_url = \"https://muckrack.com/media-outlet/wsj\"\n",
    "test_url = \"https://muckrack.com/media-outlet/washpost\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "yI99fcvXr7Vz"
   },
   "outputs": [],
   "source": [
    "r = requests.get(test_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "al_os8k_r-7P"
   },
   "outputs": [],
   "source": [
    "html_response = r.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "JyLhm8X7r_4Y"
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html_response,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "d80dUAQ_sLyu"
   },
   "outputs": [],
   "source": [
    "text = soup.find('div',{'class':\"row bottom-sm\" })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "8t0284QFsncw"
   },
   "outputs": [],
   "source": [
    "# text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "1LN_KM9ouKsL"
   },
   "outputs": [],
   "source": [
    "links = text.find_all('a')\n",
    "link_dict={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cqxRXcQmuq4S",
    "outputId": "473aa97b-f5fc-473e-9c35-192945d5ed5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Abelson, Jenn': '/jenn-abelson', 'Aberman, Jonathan': '/jaberman', 'Abernathy, Gary': '/abernathygary', 'Ables, Kelsey': '/kelsey-ables', 'Abutaleb, Yasmeen': '/yasmeen-abutaleb', 'Achenbach, Joel': '/joel-achenbach', 'Adam, Karla': '/karla-adam', 'Agawu, Emefa Addo': '/emefa-addo-agawu', 'Ahmed, Naema': '/naema-ahmed', 'Ajaka, Nadine': '/nadine-ajaka', 'Akhtar, Monica': '/monica-akhtar', 'Akkad, Reem': '/reem-akkad', 'Albergotti, Reed': '/reedalbergotti', 'Albright, Mary Beth': '/mary-beth-albright', 'Alcantara, Chris': '/chris-alcantara', 'Aldag, Jason': '/jason-aldag', 'Alemany, Jacqueline': '/jacqueline-alemany', 'Alexander, Keith L.': '/keith-alexander', 'Alfaro, Mariana': '/mariana-alfaro', 'Ali, Anjuman': '/anjuman-ali-1', 'Allan, M. Carrie': '/carrie_the_red', 'Allen, Danielle': '/danielle-allen', 'Allen, Scott': '/scott-allen', 'Althoff, Eric': '/eric-althoff', 'Alvarez, Joshua': '/joshua-alvarez', 'Alvarez, Lizette': '/lizettenyt', 'Amenabar, Teddy': '/teddy-amenabar', 'Amur, Jennifer': '/jennifer-amur', 'Anderson, Emily': '/emily-anderson-6', 'Anderson, Nick': '/wpnick', 'Andrews, Travis': '/travis-andrews', 'Andrews-Dyer, Helena': '/helena-andrews', 'Aratani, Lori': '/loriara', 'Argetsinger, Amy': '/amy-argetsinger', 'Armao, Jo-Ann': '/jo-ann-armao-1', 'Armus, Teo': '/teoarmus', 'Arthur, Nicole': '/nicolearthur', 'Attiah, Karen': '/karen-attiah', 'Aydıntaşbaş, Aslı': '/asliaydintasbas', 'Babb, Kent': '/kentbabb', 'Bade, Rachael': '/rachaelmbade', 'Bahrampour, Tara': '/tara-bahrampour', 'Bai, Matt': '/mattbai', 'Bailey, Holly': '/hollybdc', 'Balingit, Moriah': '/moriah-balingit', 'Balko, Radley': '/radleybalko', 'Balz, Dan': '/danbalz', 'Baran, Jonathan': '/jmhall_', 'Barber, Greg': '/greg-barber-1', 'Barkley, Lillian': '/lbarkle2', 'Barnes, Bart': '/bart-barnes', 'Barnes, Robert': '/robert-barnes', 'Baron, Martin': '/postbaron', 'Barr, Cameron': '/cameron-barr', 'Barr, Jeremy': '/jeremy-barr', 'Barrett, Devlin': '/devlin-barrett', 'Barrios, Jennifer': '/jennifer-barrios', 'Barron, Christina': '/christina-barron', 'Beachum, Lateshia': '/lateshia-beachum', 'Bearak, Max': '/max-bearak', 'Beck, Luisa': '/luisa-beck', 'Bell, Braden': '/braden-bell', 'Bella, Tim': '/tim-bella', 'Bendavid, Naftali': '/naftalibendavid', 'Bennett, Dalton': '/dalton-bennett', 'Benning, Victoria': '/victoria-benning', 'Berger, Miriam': '/miriam-berger', 'Berkowitz, Bonnie': '/bonnie-berkowitz', 'Berman, Jae': '/jae-berman', 'Berman, Mark': '/markberman', 'Bernstein, Adam': '/adam-bernstein', 'Bernstein, Lenny': '/lenny-bernstein', 'Betancourt, David': '/adcfanboy', 'Bethea, April': '/aprilbethea', 'Bever, Lindsey': '/lindseybever', 'Bhattarai, Abha': '/abhabhattarai', 'Bieler, Desmond': '/des-bieler', 'Binder, Sarah': '/sarah-binder', 'Birnbaum, Michael': '/michaelbirnbaum', 'Birnholz, Evan': '/evan-birnholz', 'Blackistone, Kevin B.': '/kevin-b-blackistone', 'Blake, Aaron': '/aaronblakewp', 'Blanco, Adrián': '/adrian-blanco', 'Boburg, Shawn': '/shawn-boburg', 'Bogage, Jacob': '/jacob-bogage', 'Bolek, Rachael': '/rachael-bolek', 'Bone, Julie': '/julie-bone', 'Bonesteel, Matt': '/matt-bonesteel', 'Bonne, Jon': '/jbonne', 'Bonos, Lisa': '/lisa-bonos', 'Boodman, Sandra': '/sandra-boodman', 'Boorstein, Michelle': '/michelle-boorstein', 'Boot, Max': '/max-boot-1', 'Booth, William': '/boothwilliam', 'Boren, Cindy': '/cindyboren', 'Boswell, Thomas': '/thomas-boswell', 'Botsford, Jabin': '/jabin-botsford', 'Bowen, Fred': '/fred-bowen', 'Bradley, Mark': '/mark-bradley-1', 'Branigin, William': '/william-branigin'}\n"
     ]
    }
   ],
   "source": [
    "for link in links:\n",
    " anchor_text = link.get_text()\n",
    " link_dict[anchor_text] = link['href']\n",
    "print(link_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "_y_KkvsRuuDn"
   },
   "outputs": [],
   "source": [
    "#exploring a single page\n",
    "base_url ='https://muckrack.com'\n",
    "author_url = base_url+list(link_dict.values())[3]\n",
    "# author_url_new = \"https://muckrack.com/fredrik-arnold-rydlun\"\n",
    "author_req = requests.get(author_url)\n",
    "author_text = author_req.text\n",
    "author_soup = BeautifulSoup(author_text,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "TyUpNJeSzVbV"
   },
   "outputs": [],
   "source": [
    "text = author_soup.find('div',{'class':\"profile-section-content\" })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "kNslaC9H-61r",
    "outputId": "65995d81-b5ae-4245-d866-6836fd677965"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Washington,D.C.,UnitedStates'"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location = author_soup.findAll('div',{'class':\"person-details-item person-details-location\"})[0].findAll('div')[0].get_text()\n",
    "location = re.sub('[\\n\\t\\s]*',\"\",location)\n",
    "location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "h__iZg9_AHjr",
    "outputId": "8b1c8072-6e6d-4458-8da1-95ae4e10c5e9"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Kelsey Ables'"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = text.findAll('h1')[0].get_text().split()\n",
    "name = \" \".join(x for x in name)\n",
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "nuZhL4049sod",
    "outputId": "562b9307-73a8-4d03-c62d-9e20da02dcd4"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Arts Writer — The Washington Post'"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_title = author_soup.findAll('div',{'class':\"person-details-item person-details-title\"})[0].findAll('div')[0].get_text().split()\n",
    "job_title = \" \".join(x for x in job_title)\n",
    "job_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "fCbSBRiuApJX",
    "outputId": "a29dd5a1-1c54-4d45-9ac8-0f59120cb6bc"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Arts and Entertainment,Metro D.C.,U.S.'"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interests = author_soup.findAll('div',{'class':\"person-details-item person-details-beats\"})[0].findAll('a')\n",
    "interests = \",\".join(x.get_text() for x in interests)\n",
    "interests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "YlUpgmBdFr1b",
    "outputId": "47d5cf47-a4b5-414c-ff71-f61e9c2c3b16"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-5ed323de6ea8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mverified\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauthor_soup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'small'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"profile-verified text-uppercase color-green\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mverified\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[\\s\\n]*'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverified\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mverified\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'get_text'"
     ]
    }
   ],
   "source": [
    "verified = author_soup.find('small',{'class':\"profile-verified text-uppercase color-green\"}).get_text()\n",
    "verified = re.sub('[\\s\\n]*',\"\",verified)\n",
    "verified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KM3GCARQFTc1",
    "outputId": "36d8270f-612e-4149-de52-d98c7abc3ef6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Artsy': 'https://muckrack.com/media-outlet/washpost',\n",
       " 'CNN': 'https://muckrack.com/media-outlet/washpost',\n",
       " 'Columbia Journalism Review': 'https://muckrack.com/media-outlet/washpost',\n",
       " 'Daily Herald (Chicago, IL)': 'https://muckrack.com/media-outlet/washpost',\n",
       " 'Laredo Morning Times': 'https://muckrack.com/media-outlet/washpost',\n",
       " 'Seattle Times': 'https://muckrack.com/media-outlet/washpost',\n",
       " 'Spokesman-Review': 'https://muckrack.com/media-outlet/washpost',\n",
       " 'Stars and Stripes': 'https://muckrack.com/media-outlet/washpost',\n",
       " 'Terra': 'https://muckrack.com/media-outlet/washpost',\n",
       " 'The Diplomat Magazine': 'https://muckrack.com/media-outlet/washpost',\n",
       " 'The Washington Post': 'https://muckrack.com/media-outlet/washpost',\n",
       " 'more': 'https://muckrack.com/media-outlet/washpost'}"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "as_seen_in = author_soup.find('div',{'class':\"profile-details-item\"})\n",
    "as_seen_in = {x.get_text().strip():base_url+author_soup.find('div',{'class':\"profile-details-item\"}).findAll('a')[0]['href'] for x in as_seen_in.findAll('a')}\n",
    "outlets = {}\n",
    "# if as_seen_in != None:\n",
    "#   outlets[as_seen_in] = base_url+author_soup.find('div',{'class':\"profile-details-item\"}).findAll('a')[0]['href']\n",
    "# outlets\n",
    "as_seen_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "dyoiGKgoKoyb",
    "outputId": "ed25d99e-56d6-4f6e-e996-f402bcd51a12"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'arts @washingtonpost丨former elephant reporter丨gone museuming丨previously: @artsy, @princetoninasia, @cjr, @artvoice丨columbia ‘18 丨kelsey.ables@washpost.com'"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "about = author_soup.find('div',{'class':'mr-font-size-lg mr-font-family-2 top-sm'})\n",
    "about = about.get_text().strip()\n",
    "about"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "7Do6CZn_LM9p",
    "outputId": "fff18a66-8525-49d0-f0d4-76c2cb99b9f2"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'https://pbs.twimg.com/profile_images/1233616723187728384/giIjlsxx_400x400.jpg'"
      ]
     },
     "execution_count": 39,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profile_picture_link = author_soup.find('div',{'class':'mr-profile-avatar-container col-xs-3'})\n",
    "profile_picture_link = profile_picture_link.findAll('img')[0]['src']\n",
    "profile_picture_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "wKXOb9t3NP9J"
   },
   "outputs": [],
   "source": [
    "#checking for online profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "7HnVNnWnNQD9",
    "outputId": "df623475-7582-4b2a-e9e9-3f08a5008749"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'https://t.co/e2Nux7edUE , http://twitter.com/ables_kelsey , https://www.linkedin.com/in/kelsey-ables-314774113/'"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "social = author_soup.findAll('div',{'class':'profile-section-social'})[0]\n",
    "social = \" , \".join(x['href'] for x in social.findAll('a'))\n",
    "social"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "ybVo_qN6NQIS"
   },
   "outputs": [],
   "source": [
    "# final api fuction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "09ean5ftNQPm"
   },
   "outputs": [],
   "source": [
    "test_url = \"https://muckrack.com/beat/bizfin\"\n",
    "final_frame = defaultdict(list)\n",
    "while(next_link):\n",
    "  test_req = requests.get(test_url)\n",
    "  test_html = test_req.text\n",
    "  test_soup = BeautifulSoup(test_html,'html.parser')\n",
    "  next_link = test_soup.findAll(\"ul\",{'class':'pager top-none bottom-none'})\n",
    "  try:\n",
    "    next_link = [x['href'] for x in next_link[0].find_all('a') if x.get_text().strip() == 'Next' ]\n",
    "  except:\n",
    "    next_link = None\n",
    "    break\n",
    "  link = base_url+next_link[0]\n",
    "  test_url = link\n",
    "  link_text = test_soup.find('div',{'class':\"row bottom-sm\" })\n",
    "  links = link_text.find_all('a')\n",
    "  link_dict={}\n",
    "  for link in links:\n",
    "    anchor_text = link.get_text()\n",
    "    link_dict[anchor_text] = link['href']  \n",
    "  \n",
    "  author_lis = list(link_dict.values())\n",
    "  \n",
    "  for i in range(len(author_lis)):\n",
    "    #exploring a single page\n",
    "    base_url ='https://muckrack.com'\n",
    "    author_url = base_url+author_lis[i]\n",
    "    # author_url_new = \"https://muckrack.com/fredrik-arnold-rydlun\"\n",
    "    author_req = requests.get(author_url)\n",
    "    author_text = author_req.text\n",
    "    author_soup = BeautifulSoup(author_text,'html.parser')\n",
    "    try:\n",
    "      location = author_soup.findAll('div',{'class':\"person-details-item person-details-location\"})\n",
    "      location = re.sub('[\\n\\t\\s]*',\"\",location[0].findAll('div')[0].get_text()) if location else \" \"\n",
    "      \n",
    "      name = author_soup.findAll('h1')\n",
    "      name = \" \".join(x for x in name[0].get_text().split()) if name != [] else \" \"\n",
    "      \n",
    "      job_title = author_soup.findAll('div',{'class':\"person-details-item person-details-title\"})\n",
    "      job_title = \" \".join(x for x in job_title[0].findAll('div')[0].get_text().split()) if job_title else \" \" \n",
    "      \n",
    "      interests = author_soup.findAll('div',{'class':\"person-details-item person-details-beats\"})[0].findAll('a')\n",
    "      interests = \",\".join(x.get_text() for x in interests) if interests else \" \"\n",
    "      \n",
    "      verified = author_soup.find('small',{'class':\"profile-verified text-uppercase color-green\"})\n",
    "      verified = re.sub('[\\s\\n]*',\"\",verified.get_text()) if verified else 'Not Verified' \n",
    "      \n",
    "      as_seen_in = author_soup.find('div',{'class':\"profile-details-item\"})\n",
    "      as_seen_in = {x.get_text().strip():base_url+x['href'] for x in as_seen_in.findAll('a')} if as_seen_in else None\n",
    "\n",
    "      \n",
    "      about = author_soup.find('div',{'class':'mr-font-size-lg mr-font-family-2 top-sm'})\n",
    "      about = about.get_text().strip() if about else \" \"\n",
    "      \n",
    "      # profile_picture_link = author_soup.find('div',{'class':'mr-profile-avatar-container col-xs-3'})\n",
    "      # profile_picture_link = profile_picture_link.findAll('img')[0]['src']\n",
    "      \n",
    "      main_social = author_soup.findAll('div',{'class':'profile-section-social'})\n",
    "      main_social = \",\".join(x['href'] for x in main_social[0].findAll('a')) if main_social else None\n",
    "      other_social = []\n",
    "      facebook = None\n",
    "      linkdin = None\n",
    "      twitter = None\n",
    "      if main_social == None:\n",
    "        other_social = main_social\n",
    "        facebook = None\n",
    "        linkdin = None\n",
    "        twitter = None\n",
    "      else:\n",
    "        for website in main_social.split(','):\n",
    "          if 'facebook' in website:\n",
    "            facebook = website\n",
    "            \n",
    "          elif 'linkedin' in website:\n",
    "            linkdin = website\n",
    "          elif 'twitter' in website:\n",
    "            twitter = website\n",
    "            \n",
    "          else:\n",
    "            other_social.append(website)\n",
    "      \n",
    "\n",
    "      \n",
    "\n",
    "      # print(name , job_title , interests , verified , as_seen_in , about , profile_picture_link ,social)\n",
    "    except Exception as e:\n",
    "      print('some error',e)\n",
    "      continue\n",
    "\n",
    "\n",
    "    final_frame['author_name'].append(name)\n",
    "    final_frame['job_title'].append(job_title)\n",
    "    final_frame['location'].append(interests)\n",
    "    final_frame['verified'].append(verified)\n",
    "    final_frame['outlets'].append(as_seen_in)\n",
    "    final_frame['about'].append(about)\n",
    "    # final_frame['profile_picture_link'].append(profile_picture_link)\n",
    "    final_frame['other_social'].append(other_social)\n",
    "    final_frame['facebook'].append(facebook)\n",
    "    final_frame['linkedin'].append(linkdin)\n",
    "    final_frame['twitter'].append(twitter)\n",
    "  print(final_frame.keys())\n",
    "  #capture href of outlets very very imp\n",
    "  #sep facebook /mukrak profile scrapping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VfB2APRPUPDU",
    "outputId": "98bd7035-7de5-41d0-e487-7be2590823b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26064 entries, 0 to 26063\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   author_name   26064 non-null  object\n",
      " 1   job_title     26064 non-null  object\n",
      " 2   location      26064 non-null  object\n",
      " 3   verified      26064 non-null  object\n",
      " 4   outlets       25629 non-null  object\n",
      " 5   about         26064 non-null  object\n",
      " 6   other_social  24931 non-null  object\n",
      " 7   facebook      10997 non-null  object\n",
      " 8   linkedin      22762 non-null  object\n",
      "dtypes: object(9)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "frame = pd.DataFrame(final_frame)\n",
    "frame.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WV_7RRD1SW3F",
    "outputId": "f4bba3de-45f7-446f-9d33-19d0a47f18c8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'facebook' in 'facebook.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bAWfFnvtKC-P",
    "outputId": "85740639-2ff6-42c9-a11f-ef689d5a7d1e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Fit Small Business': 'https://muckrack.com/media-outlet/fitsmallbusiness',\n",
       " 'Hillsboro Banner': 'https://muckrack.com/media-outlet/hillsborobanner'}"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame.outlets.iloc[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "ZxRsVrMhNQT9"
   },
   "outputs": [],
   "source": [
    "frame.to_csv('authors_final_big_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "wIsg_csmWzX2"
   },
   "outputs": [],
   "source": [
    "test_req = requests.get(test_url)\n",
    "test_html = test_req.text\n",
    "test_soup = BeautifulSoup(test_html,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pGFrAt4eNQXp"
   },
   "outputs": [],
   "source": [
    "test_url = \"https://muckrack.com/beat/bizfin\"\n",
    "next_link = True\n",
    "while(next_link):\n",
    "  test_req = requests.get(test_url)\n",
    "  test_html = test_req.text\n",
    "  test_soup = BeautifulSoup(test_html,'html.parser')\n",
    "  next_link = test_soup.findAll(\"ul\",{'class':'pager top-none bottom-none'})\n",
    "  try:\n",
    "    next_link = [x['href'] for x in next_link[0].find_all('a') if x.get_text().strip() == 'Next' ]\n",
    "  except:\n",
    "    next_link == None\n",
    "    break\n",
    "  link = base_url+next_link[0]\n",
    "  test_url = link\n",
    "  link_text = test_soup.find('div',{'class':\"row bottom-sm\" })\n",
    "  links = link_text.find_all('a')\n",
    "  link_dict={}\n",
    "  for link in links:\n",
    "    anchor_text = link.get_text()\n",
    "    link_dict[anchor_text] = link['href']\n",
    "  print(link_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hjxGC8a917ld"
   },
   "source": [
    "\n",
    "## Implementing final functions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "VEmaRLOV2BqA"
   },
   "outputs": [],
   "source": [
    "def Get_author_list(outlet):\n",
    "  '''\n",
    "  returns dictionary with\n",
    "  keys: author names\n",
    "  values: Profile links\n",
    "\n",
    "  requires requests,beautifulsoup Module\n",
    "  '''\n",
    "  author_dict = {}\n",
    "  base_url = \"https://muckrack.com\"\n",
    "  test_url =base_url+\"/media-outlet/\"+outlet\n",
    "  author_lis = []\n",
    "  link_dict={}\n",
    "  # print(test_url)\n",
    "  while (True):\n",
    "    test_req = requests.get(test_url)\n",
    "    test_html = test_req.text\n",
    "    test_soup = BeautifulSoup(test_html,'html.parser')\n",
    "    next_link = test_soup.findAll(\"ul\",{'class':'pager top-none bottom-none'})\n",
    "    # print(next_link)\n",
    "    try:\n",
    "      next_link = [x['href'] for x in next_link[0].find_all('a') if x.get_text().strip() == 'Next' ]\n",
    "    except:\n",
    "      next_link = None\n",
    "      break\n",
    "    link = base_url+next_link[0]\n",
    "    test_url = link\n",
    "    # print(link)\n",
    "    link_text = test_soup.find('div',{'class':\"row bottom-sm\" })\n",
    "    links = link_text.find_all('a')\n",
    "    \n",
    "    for link in links:\n",
    "      anchor_text = link.get_text()\n",
    "      link_dict[anchor_text] = base_url+link['href']  \n",
    "      \n",
    "    \n",
    "  return link_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S4Qku_9tDFsh"
   },
   "source": [
    "second\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "5HOlrBvZ4Mbj"
   },
   "outputs": [],
   "source": [
    "x = Get_author_list('wsj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "VnCFdTJL4gUa"
   },
   "outputs": [],
   "source": [
    "def Get_author_data(author_link_list):\n",
    "  '''\n",
    "  Takes in a input of list and returns the author details in data frame format \n",
    "\n",
    "\n",
    "  input: List of the links of author profiles \n",
    "\n",
    "  output: Dataframe containing all the author details \n",
    "  \n",
    "  requires defaultdict and pandas to be imported\n",
    "  '''\n",
    "  final_frame = defaultdict(list)\n",
    "  base_url = \"https://muckrack.com\"\n",
    "  for author_link in author_link_list:\n",
    "    author_req = requests.get(author_link)\n",
    "    author_text = author_req.text\n",
    "    author_soup = BeautifulSoup(author_text,'html.parser')\n",
    "    try:\n",
    "      location = author_soup.findAll('div',{'class':\"person-details-item person-details-location\"})\n",
    "      location = re.sub('[\\n\\t\\s]*',\"\",location[0].findAll('div')[0].get_text()) if location else \" \"\n",
    "      \n",
    "      name = author_soup.findAll('h1')\n",
    "      name = \" \".join(x for x in name[0].get_text().split()) if name != [] else \" \"\n",
    "      \n",
    "      job_title = author_soup.findAll('div',{'class':\"person-details-item person-details-title\"})\n",
    "      job_title = \" \".join(x for x in job_title[0].findAll('div')[0].get_text().split()) if job_title else \" \" \n",
    "      \n",
    "      interests = author_soup.findAll('div',{'class':\"person-details-item person-details-beats\"})\n",
    "      try:\n",
    "        interests = interests[0].findAll('a')\n",
    "        interests = \",\".join(x.get_text() for x in interests) if interests else \" \"\n",
    "      except:\n",
    "        interests  = None\n",
    "      \n",
    "      verified = author_soup.find('small',{'class':\"profile-verified text-uppercase color-green\"})\n",
    "      verified = re.sub('[\\s\\n]*',\"\",verified.get_text()) if verified else 'Not Verified' \n",
    "      \n",
    "      as_seen_in = author_soup.find('div',{'class':\"profile-details-item\"})\n",
    "      as_seen_in = {x.get_text().strip():base_url+x['href'] for x in as_seen_in.findAll('a')} if as_seen_in else None\n",
    "\n",
    "      \n",
    "      about = author_soup.find('div',{'class':'mr-font-size-lg mr-font-family-2 top-sm'})\n",
    "      about = about.get_text().strip() if about else \" \"\n",
    "      \n",
    "      # profile_picture_link = author_soup.find('div',{'class':'mr-profile-avatar-container col-xs-3'})\n",
    "      # profile_picture_link = profile_picture_link.findAll('img')[0]['src']\n",
    "      \n",
    "      main_social = author_soup.findAll('div',{'class':'profile-section-social'})\n",
    "      main_social = \",\".join(x['href'] for x in main_social[0].findAll('a')) if main_social else None\n",
    "      other_social = []\n",
    "      facebook = None\n",
    "      linkdin = None\n",
    "      twitter = None\n",
    "      if main_social == None:\n",
    "        other_social = main_social\n",
    "        facebook = None\n",
    "        linkdin = None\n",
    "        twitter = None\n",
    "      else:\n",
    "        for website in main_social.split(','):\n",
    "          if 'facebook' in website:\n",
    "            facebook = website\n",
    "            \n",
    "          elif 'linkedin' in website:\n",
    "            linkdin = website\n",
    "          elif 'twitter' in website:\n",
    "            twitter = website\n",
    "            \n",
    "          else:\n",
    "            other_social.append(website)\n",
    "      \n",
    "      \n",
    "\n",
    "      \n",
    "\n",
    "        # print(name , job_title , interests , verified , as_seen_in , about , profile_picture_link ,social)\n",
    "    except Exception as e:\n",
    "      print(name)\n",
    "      print('some error',e)\n",
    "      \n",
    "    final_frame['author_name'].append(name)\n",
    "    final_frame['job_title'].append(job_title)\n",
    "    final_frame['location'].append(interests)\n",
    "    final_frame['verified'].append(verified)\n",
    "    final_frame['outlets'].append(as_seen_in)\n",
    "    final_frame['about'].append(about)\n",
    "    # final_frame['profile_picture_link'].append(profile_picture_link)\n",
    "    final_frame['other_social'].append(other_social)\n",
    "    final_frame['facebook'].append(facebook)\n",
    "    final_frame['linkedin'].append(linkdin)\n",
    "    final_frame['twitter'].append(twitter)\n",
    "  final_frame = pd.DataFrame(final_frame)\n",
    "  return final_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OYrQ1keA-cQL"
   },
   "outputs": [],
   "source": [
    "test = list(x.values())[:30]\n",
    "Get_author_data(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zcpuolLo_XiO"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPFfJlrPgiwy9cd2A8D45HQ",
   "include_colab_link": true,
   "name": "scrapping.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
