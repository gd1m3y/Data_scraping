{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "overhead-quest",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nitter_scraper import NitterScraper,get_tweets\n",
    "from nitter_scraper.profile import parse_user_id_from_banner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "religious-insured",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from pprint import pprint\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "minus-seven",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = pd.read_csv('C:/Users/naray/OneDrive/Desktop/wash_post_revised.csv')\n",
    "frame = frame.drop(frame.columns[0],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "tough-plane",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = frame.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "greek-region",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jaberman'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_profile = frame.twitter.iloc[1]\n",
    "x = test_profile.split('/')[-1]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "future-edinburgh",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://nitter.net\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "victorian-butler",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_url = base_url+'/'+x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "divided-christianity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://nitter.net/jaberman'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "tested-treasury",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(author_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "adopted-ability",
   "metadata": {},
   "outputs": [],
   "source": [
    "html = r.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fantastic-control",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_soup = BeautifulSoup(html,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "eight-header",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jonathan Aberman'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#author name\n",
    "author_name = author_soup.find('a',{'class':'profile-card-fullname'})\n",
    "author_name = author_name.text if author_name else None\n",
    "author_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "guided-handle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@jaberman'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#twitter username\n",
    "twitter_username = author_soup.find('a',{'class':'profile-card-username'})\n",
    "twitter_username = twitter_username.text if twitter_username else None\n",
    "twitter_username"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "deadly-vintage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Verified account'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verfied\n",
    "verified = author_soup.find('span',{'class':'icon-ok verified-icon'})\n",
    "verified = verified['title'] if verified else \"Not verified account\"\n",
    "verified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "dutch-columbia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://nitter.net/pic/profile_images%2F495568319840137217%2FXr2UHBrZ.jpeg'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#profile picture link \n",
    "profile_picture = author_soup.find('a',{'class':'profile-card-avatar'})\n",
    "profile_picture = base_url+profile_picture['href'] if profile_picture else None\n",
    "profile_picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "tough-capitol",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'495568319840137217'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#user id\n",
    "user_id = parse_user_id_from_banner(profile_picture)\n",
    "user_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "incredible-shoot",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Innovation and entrepreneurship expert. Founder Amplifier Advisors, Dean Marymount University SBT. Host @whatsworkingDC. Columnist @wbjonline'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#profile bio\n",
    "profile_bio = author_soup.find('div',{'class':'profile-bio'})\n",
    "profile_bio = profile_bio.text if profile_bio else None\n",
    "profile_bio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "authorized-consciousness",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'McLean, Virginia'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#profile location\n",
    "profile_location = author_soup.find('div',{'class':'profile-location'})\n",
    "profile_location = profile_location.text.strip() if profile_location else None\n",
    "profile_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "classified-lightweight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jonathanaberman.com'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#profile website\n",
    "profile_website = author_soup.find('div',{'class':'profile-website'})\n",
    "profile_website = profile_website.text.strip() if profile_website else None\n",
    "profile_website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "widespread-multimedia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'11:09 AM - 13 Jun 2008'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#profile join date\n",
    "profile_join_date = author_soup.find('div',{'class':'profile-joindate'})\n",
    "profile_join_date = profile_join_date.find_all('span')[0]['title'] if profile_join_date else None\n",
    "profile_join_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "quality-bridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NO of posts\n",
    "no_of_posts = author_soup.find('li',{'class':'posts'})\n",
    "no_of_posts = no_of_posts.find('span',{'class':'profile-stat-num'}).text if no_of_posts else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "amber-syndication",
   "metadata": {},
   "outputs": [],
   "source": [
    "#no of following\n",
    "no_of_following = author_soup.find('li',{'class':'following'})\n",
    "no_of_following = no_of_following.find('span',{'class':'profile-stat-num'}).text if no_of_following else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "hearing-factor",
   "metadata": {},
   "outputs": [],
   "source": [
    "#no of followers\n",
    "followers = author_soup.find('li',{'class':'followers'})\n",
    "followers = followers.find('span',{'class':'profile-stat-num'}).text if followers else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "indonesian-equality",
   "metadata": {},
   "outputs": [],
   "source": [
    "likes = author_soup.find('li',{'class':'likes'})\n",
    "likes = likes.find('span',{'class':'profile-stat-num'}).text if likes else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incredible-morrison",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "consecutive-employment",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet = get_tweets('agarwalvibhuti',pages=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "enabling-alarm",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-113-055e71138083>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtweet\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mlis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\naray\\anaconda3\\envs\\scrapper\\lib\\site-packages\\nitter_scraper\\tweets.py\u001b[0m in \u001b[0;36mget_tweets\u001b[1;34m(username, pages, break_on_tweet_id, address)\u001b[0m\n\u001b[0;32m    178\u001b[0m             \u001b[0mpages\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m     \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgen_tweets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\naray\\anaconda3\\envs\\scrapper\\lib\\site-packages\\nitter_scraper\\tweets.py\u001b[0m in \u001b[0;36mgen_tweets\u001b[1;34m(pages)\u001b[0m\n\u001b[0;32m    158\u001b[0m                 \u001b[0mtimeline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtimeline_parser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhtml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m                 \u001b[0mnext_url\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpagination_parser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maddress\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0musername\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m                 \u001b[0mtimeline_items\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtimeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\".timeline-item\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\naray\\anaconda3\\envs\\scrapper\\lib\\site-packages\\nitter_scraper\\tweets.py\u001b[0m in \u001b[0;36mpagination_parser\u001b[1;34m(timeline, address, username)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpagination_parser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maddress\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0musername\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m     \u001b[0mnext_page\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\".show-more\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;34mf\"{address}/{username}{next_page}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find'"
     ]
    }
   ],
   "source": [
    "lis = []\n",
    "for x in tweet:\n",
    "    lis.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "fundamental-portuguese",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_dict ={}\n",
    "for i in range(len(lis)):\n",
    "    for j in lis:\n",
    "        for key,value in list(j):\n",
    "            if i in tweets_dict.keys():\n",
    "                tweets_dict[i][key] = value\n",
    "            else:\n",
    "                tweets_dict[i] = {}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "impossible-dominican",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "pprint(tweets_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "nearby-college",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_twitter_profile(author_list):\n",
    "    final_dict = defaultdict(list)\n",
    "    for author in author_list:\n",
    "        x = author.split('/')[-1]\n",
    "        base_url = \"https://nitter.net\"\n",
    "        author_url = base_url+'/'+x\n",
    "        r = requests.get(author_url)\n",
    "        html = r.text\n",
    "        author_soup = BeautifulSoup(html,'html.parser')\n",
    "        #author name\n",
    "        author_name = author_soup.find('a',{'class':'profile-card-fullname'})\n",
    "        author_name = author_name.text if author_name else None\n",
    "\n",
    "        #twitter username\n",
    "        twitter_username = author_soup.find('a',{'class':'profile-card-username'})\n",
    "        twitter_username = twitter_username.text if twitter_username else None\n",
    "\n",
    "        #verfied\n",
    "        verified = author_soup.find('span',{'class':'icon-ok verified-icon'})\n",
    "        verified = verified['title'] if verified else \"Not verified account\"\n",
    "\n",
    "        #profile picture link \n",
    "        profile_picture = author_soup.find('a',{'class':'profile-card-avatar'})\n",
    "        profile_picture = base_url+profile_picture['href'] if profile_picture else None\n",
    "\n",
    "\n",
    "        #user id\n",
    "        user_id = parse_user_id_from_banner(profile_picture) if profile_picture else None\n",
    "\n",
    "\n",
    "        #profile bio\n",
    "        profile_bio = author_soup.find('div',{'class':'profile-bio'})\n",
    "        profile_bio = profile_bio.text if profile_bio else None\n",
    "\n",
    "            #profile location\n",
    "        profile_location = author_soup.find('div',{'class':'profile-location'})\n",
    "        profile_location = profile_location.text.strip() if profile_location else None\n",
    "\n",
    "            #profile website\n",
    "        profile_website = author_soup.find('div',{'class':'profile-website'})\n",
    "        profile_website = profile_website.text.strip() if profile_website else None\n",
    "\n",
    "        #profile join date\n",
    "        profile_join_date = author_soup.find('div',{'class':'profile-joindate'})\n",
    "        profile_join_date = profile_join_date.find_all('span')[0]['title'] if profile_join_date else None\n",
    "\n",
    "        #NO of posts\n",
    "        no_of_posts = author_soup.find('li',{'class':'posts'})\n",
    "        no_of_posts = no_of_posts.find('span',{'class':'profile-stat-num'}).text if no_of_posts else None\n",
    "\n",
    "        #no of following\n",
    "        no_of_following = author_soup.find('li',{'class':'following'})\n",
    "        no_of_following = no_of_following.find('span',{'class':'profile-stat-num'}).text if no_of_following else None\n",
    "\n",
    "        #no of followers\n",
    "        followers = author_soup.find('li',{'class':'followers'})\n",
    "        followers = followers.find('span',{'class':'profile-stat-num'}).text if followers else None\n",
    "\n",
    "        #no of likes\n",
    "        likes = author_soup.find('li',{'class':'likes'})\n",
    "        likes = likes.find('span',{'class':'profile-stat-num'}).text if likes else None\n",
    "        try:\n",
    "            tweet = get_tweets(x,pages=1)\n",
    "\n",
    "            lis = []\n",
    "            for x in tweet:\n",
    "                lis.append(x)\n",
    "\n",
    "            tweets_dict ={}\n",
    "            for i in range(len(lis)):\n",
    "                for j in lis:\n",
    "                    for key,value in list(j):\n",
    "                        if i in tweets_dict.keys():\n",
    "                            tweets_dict[i][key] = value\n",
    "                        else:\n",
    "                            tweets_dict[i] = {}\n",
    "        except:\n",
    "            print(x)\n",
    "            tweets_dict = 'Protected Account'\n",
    "        final_dict['author_name'].append(author_name)\n",
    "        final_dict['twitter_username'].append(twitter_username)\n",
    "        final_dict['verified'].append(verified)\n",
    "        final_dict['profile_picture'].append(profile_picture)\n",
    "        final_dict['user_id'].append(user_id)\n",
    "        final_dict['bio'].append(profile_bio)\n",
    "        final_dict['profile_location'].append(profile_location)\n",
    "        final_dict['profile_website'].append(profile_website)\n",
    "        final_dict['profile_join_date'].append(profile_join_date)\n",
    "        final_dict['no_of_posts'].append(no_of_posts)\n",
    "        final_dict['following'].append(no_of_following)\n",
    "        final_dict['followers'].append(followers)\n",
    "        final_dict['likes'].append(likes)\n",
    "        final_dict['tweet'].append(tweets_dict)\n",
    "    return pd.DataFrame(final_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "personalized-turner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emilycodik\n",
      "mrwduffy\n",
      "dugganwapo\n",
      "Ms_AmberDawn\n",
      "BrianFMurphy\n",
      "MrErinO\n",
      "kpagekirby\n",
      "Kat_A_Powers\n"
     ]
    }
   ],
   "source": [
    "new_frame = scrap_twitter_profile(list(frame.twitter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "moderate-sleeping",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_name</th>\n",
       "      <th>twitter_username</th>\n",
       "      <th>verified</th>\n",
       "      <th>profile_picture</th>\n",
       "      <th>user_id</th>\n",
       "      <th>bio</th>\n",
       "      <th>profile_location</th>\n",
       "      <th>profile_website</th>\n",
       "      <th>profile_join_date</th>\n",
       "      <th>no_of_posts</th>\n",
       "      <th>following</th>\n",
       "      <th>followers</th>\n",
       "      <th>likes</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jenn Abelson</td>\n",
       "      <td>@jennabelson</td>\n",
       "      <td>Verified account</td>\n",
       "      <td>https://nitter.net/pic/profile_images%2F870738...</td>\n",
       "      <td>870738381084536833</td>\n",
       "      <td>Investigative reporter @WashingtonPost and co-...</td>\n",
       "      <td>None</td>\n",
       "      <td>jennabelson.com</td>\n",
       "      <td>10:08 PM - 26 Nov 2008</td>\n",
       "      <td>2,997</td>\n",
       "      <td>2,334</td>\n",
       "      <td>5,528</td>\n",
       "      <td>1,435</td>\n",
       "      <td>{0: {'tweet_url': '/bylenasun/status/134868494...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jonathan Aberman</td>\n",
       "      <td>@jaberman</td>\n",
       "      <td>Verified account</td>\n",
       "      <td>https://nitter.net/pic/profile_images%2F495568...</td>\n",
       "      <td>495568319840137217</td>\n",
       "      <td>Innovation and entrepreneurship expert. Founde...</td>\n",
       "      <td>McLean, Virginia</td>\n",
       "      <td>jonathanaberman.com</td>\n",
       "      <td>11:09 AM - 13 Jun 2008</td>\n",
       "      <td>6,291</td>\n",
       "      <td>695</td>\n",
       "      <td>3,510</td>\n",
       "      <td>148</td>\n",
       "      <td>{0: {'tweet_url': '/jaberman/status/1176241155...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yasmeen Abutaleb</td>\n",
       "      <td>@yabutaleb7</td>\n",
       "      <td>Verified account</td>\n",
       "      <td>https://nitter.net/pic/profile_images%2F127021...</td>\n",
       "      <td>1270219484192813057</td>\n",
       "      <td>Health policy reporter @washingtonpost. Former...</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>washingtonpost.com/newssearc…</td>\n",
       "      <td>1:32 AM - 22 Nov 2011</td>\n",
       "      <td>4,611</td>\n",
       "      <td>1,946</td>\n",
       "      <td>15,665</td>\n",
       "      <td>2,236</td>\n",
       "      <td>{0: {'tweet_url': '/jdawsey1/status/1344428800...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Karla Adam</td>\n",
       "      <td>@karlaadam</td>\n",
       "      <td>Verified account</td>\n",
       "      <td>https://nitter.net/pic/profile_images%2F520650...</td>\n",
       "      <td>520650331475410945</td>\n",
       "      <td>London correspondent for The Washington Post. ...</td>\n",
       "      <td>London</td>\n",
       "      <td>washingtonpost.com/people/ka…</td>\n",
       "      <td>11:39 AM - 16 Apr 2009</td>\n",
       "      <td>5,331</td>\n",
       "      <td>2,737</td>\n",
       "      <td>3,509</td>\n",
       "      <td>2,517</td>\n",
       "      <td>{0: {'tweet_url': '/maggiepenman/status/134699...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Reem Akkad</td>\n",
       "      <td>@reemakkad</td>\n",
       "      <td>Verified account</td>\n",
       "      <td>https://nitter.net/pic/profile_images%2F739260...</td>\n",
       "      <td>739260627630346240</td>\n",
       "      <td>Senior Producer- Washington Post @PostVideo, N...</td>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>washingtonpost.com</td>\n",
       "      <td>2:22 PM - 14 Feb 2009</td>\n",
       "      <td>2,549</td>\n",
       "      <td>4,652</td>\n",
       "      <td>2,251</td>\n",
       "      <td>2,381</td>\n",
       "      <td>{0: {'tweet_url': '/ZoeannMurphy/status/134700...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        author_name twitter_username          verified  \\\n",
       "0      Jenn Abelson     @jennabelson  Verified account   \n",
       "1  Jonathan Aberman        @jaberman  Verified account   \n",
       "2  Yasmeen Abutaleb      @yabutaleb7  Verified account   \n",
       "3        Karla Adam       @karlaadam  Verified account   \n",
       "4        Reem Akkad       @reemakkad  Verified account   \n",
       "\n",
       "                                     profile_picture              user_id  \\\n",
       "0  https://nitter.net/pic/profile_images%2F870738...   870738381084536833   \n",
       "1  https://nitter.net/pic/profile_images%2F495568...   495568319840137217   \n",
       "2  https://nitter.net/pic/profile_images%2F127021...  1270219484192813057   \n",
       "3  https://nitter.net/pic/profile_images%2F520650...   520650331475410945   \n",
       "4  https://nitter.net/pic/profile_images%2F739260...   739260627630346240   \n",
       "\n",
       "                                                 bio  profile_location  \\\n",
       "0  Investigative reporter @WashingtonPost and co-...              None   \n",
       "1  Innovation and entrepreneurship expert. Founde...  McLean, Virginia   \n",
       "2  Health policy reporter @washingtonpost. Former...    Washington, DC   \n",
       "3  London correspondent for The Washington Post. ...            London   \n",
       "4  Senior Producer- Washington Post @PostVideo, N...   Washington D.C.   \n",
       "\n",
       "                 profile_website       profile_join_date no_of_posts  \\\n",
       "0                jennabelson.com  10:08 PM - 26 Nov 2008       2,997   \n",
       "1            jonathanaberman.com  11:09 AM - 13 Jun 2008       6,291   \n",
       "2  washingtonpost.com/newssearc…   1:32 AM - 22 Nov 2011       4,611   \n",
       "3  washingtonpost.com/people/ka…  11:39 AM - 16 Apr 2009       5,331   \n",
       "4             washingtonpost.com   2:22 PM - 14 Feb 2009       2,549   \n",
       "\n",
       "  following followers  likes  \\\n",
       "0     2,334     5,528  1,435   \n",
       "1       695     3,510    148   \n",
       "2     1,946    15,665  2,236   \n",
       "3     2,737     3,509  2,517   \n",
       "4     4,652     2,251  2,381   \n",
       "\n",
       "                                               tweet  \n",
       "0  {0: {'tweet_url': '/bylenasun/status/134868494...  \n",
       "1  {0: {'tweet_url': '/jaberman/status/1176241155...  \n",
       "2  {0: {'tweet_url': '/jdawsey1/status/1344428800...  \n",
       "3  {0: {'tweet_url': '/maggiepenman/status/134699...  \n",
       "4  {0: {'tweet_url': '/ZoeannMurphy/status/134700...  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "gross-samba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 469 entries, 0 to 468\n",
      "Data columns (total 14 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   author_name        467 non-null    object\n",
      " 1   twitter_username   467 non-null    object\n",
      " 2   verified           469 non-null    object\n",
      " 3   profile_picture    467 non-null    object\n",
      " 4   user_id            467 non-null    object\n",
      " 5   bio                458 non-null    object\n",
      " 6   profile_location   406 non-null    object\n",
      " 7   profile_website    377 non-null    object\n",
      " 8   profile_join_date  467 non-null    object\n",
      " 9   no_of_posts        467 non-null    object\n",
      " 10  following          467 non-null    object\n",
      " 11  followers          467 non-null    object\n",
      " 12  likes              467 non-null    object\n",
      " 13  tweet              469 non-null    object\n",
      "dtypes: object(14)\n",
      "memory usage: 51.4+ KB\n"
     ]
    }
   ],
   "source": [
    "new_frame.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "proprietary-blast",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_frame.to_csv('wash_post_authors_twitter.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quarterly-token",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
